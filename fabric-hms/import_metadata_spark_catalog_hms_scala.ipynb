{"cells":[{"cell_type":"code","execution_count":9,"id":"6f71db72-a0e4-4953-83b7-60d378cd6696","metadata":{"microsoft":{"language":"scala"}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2023-07-19T14:40:40.3018899Z","execution_start_time":"2023-07-19T14:40:37.9131404Z","livy_statement_state":"available","parent_msg_id":"a39f1b2d-ceb6-43e9-a56e-25df3a50cdab","queued_time":"2023-07-19T14:40:37.6129159Z","session_id":"1a4eefc7-d154-4be6-86ae-4bcafe8aed92","session_start_time":null,"spark_jobs":{"jobs":[],"limit":20,"numbers":{"FAILED":0,"RUNNING":0,"SUCCEEDED":0,"UNKNOWN":0},"rule":"ALL_DESC"},"spark_pool":null,"state":"finished","statement_id":11},"text/plain":["StatementMeta(, 1a4eefc7-d154-4be6-86ae-4bcafe8aed92, 11, Finished, Available)"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["IntermediateFolderPath: String = abfss://default@stmurgguhms.dfs.core.windows.net/hms_output/blog/hditwodbs\n","StorageAccountName: String = stmurgguhms\n","StorageAccountAccessKey: String = hpT0lcfexvkmTgZ12hFedS2jxAO32CsqOhNpoUFXiouNgDQJvPxbyNzK636y049GNsH6dl/oNiYq+AStOMKJHQ==\n","WorkspaceId: String = c3c00e15-8713-4764-a9dc-43a64cf49eaa\n","LakehouseId: String = 2e2668a7-9b73-478c-89cc-9ebfbad83a0b\n","WarehouseMappings: scala.collection.mutable.Map[String,String] = Map(abfss://hdi-murggu-hms-2023-07-19t13-27-53-906z@stmurgguhms.dfs.core.windows.net/apps/spark/warehouse -> abfss://c3c00e15-8713-4764-a9dc-43a64cf49eaa@msit-onelake.dfs.fabric.microsoft.com/2e2668a7-9b73-478c-89cc-9ebfbad83a0b/Files/warehouse_dir_hdi, dbfs:/mnt/stmurgguhms/databricks/warehouse -> abfss://c3c00e15-8713-4764-a9dc-43a64cf49eaa@msit-onelake.dfs.fabric.microsoft.com/2e2668a7-9b73-478c-89cc-9ebfbad83a0b/Files/warehouse_dir_dbx, abfss://default@stmurgguhms.dfs.core.windows.net/synapse/workspaces/syn-murggu-hms/warehouse -> abfss://c3c00e15-8713-4764-a9dc-43a64cf49eaa@msit-onelake.dfs.fabric.microsoft.com/2e2668a7-9b73-478c-89cc-9ebfbad83a0b/Files/warehouse_dir_syn)\n","DatabasePrefix: String = \"\"\n","TablePrefix: String = \"\"\n","IgnoreIfExists: Boolean = true\n"]}],"source":["%%spark\n","// Intermediate ADLS Gen2 config\n","var IntermediateFolderPath = \"abfss://<container>@<storage_name>.dfs.core.windows.net/hms_output/syn/\"\n","var StorageAccountName = \"stmurgguhms\"\n","var StorageAccountAccessKey = \"<storage_account_key>\"\n","\n","// Fabric config\n","var WorkspaceId = \"c3c00e15-8713-4764-a9dc-43a64cf49eaa\"\n","var LakehouseId = \"2e2668a7-9b73-478c-89cc-9ebfbad83a0b\"\n","var WarehouseMappings:Map[String, String] = Map(\n","    \"abfss://default@stmurgguhms.dfs.core.windows.net/synapse/workspaces/syn-murggu-hms/warehouse\"-> f\"abfss://${WorkspaceId}@msit-onelake.dfs.fabric.microsoft.com/${LakehouseId}/Files/warehouse_dir_syn\",\n","    \"dbfs:/mnt/stmurgguhms/databricks/warehouse\"->f\"abfss://${WorkspaceId}@msit-onelake.dfs.fabric.microsoft.com/${LakehouseId}/Files/warehouse_dir_dbx\",\n","    \"abfss://hdi-murggu-hms-2023-07-19t13-27-53-906z@stmurgguhms.dfs.core.windows.net/apps/spark/warehouse\"->f\"abfss://${WorkspaceId}@msit-onelake.dfs.fabric.microsoft.com/${LakehouseId}/Files/warehouse_dir_hdi\"\n",")\n","\n","// Metastore config\n","var DatabasePrefix = \"\"\n","var TablePrefix = \"\"\n","var IgnoreIfExists = true"]},{"cell_type":"code","execution_count":2,"id":"dbfb1b8e-55cd-4589-9c7f-7d020a3b161e","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"scala"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2023-07-19T14:37:25.9991738Z","execution_start_time":"2023-07-19T14:37:25.1552829Z","livy_statement_state":"available","parent_msg_id":"6d230e79-258f-4bbb-8788-b167f99dd883","queued_time":"2023-07-19T14:37:24.8811448Z","session_id":"1a4eefc7-d154-4be6-86ae-4bcafe8aed92","session_start_time":null,"spark_jobs":{"jobs":[],"limit":20,"numbers":{"FAILED":0,"RUNNING":0,"SUCCEEDED":0,"UNKNOWN":0},"rule":"ALL_DESC"},"spark_pool":null,"state":"finished","statement_id":4},"text/plain":["StatementMeta(, 1a4eefc7-d154-4be6-86ae-4bcafe8aed92, 4, Finished, Available)"]},"metadata":{},"output_type":"display_data"}],"source":["%%spark\n","spark.conf.set(\n","  \"fs.azure.account.key.\" + StorageAccountName + \".dfs.core.windows.net\",\n","  StorageAccountAccessKey\n",")"]},{"cell_type":"code","execution_count":3,"id":"347ad4ed-313b-4836-9b8f-1a0125b00376","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"scala"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2023-07-19T14:37:38.2248446Z","execution_start_time":"2023-07-19T14:37:28.1963217Z","livy_statement_state":"available","parent_msg_id":"a8256e37-edb4-4c4e-94ac-0f353d553a03","queued_time":"2023-07-19T14:37:27.8064799Z","session_id":"1a4eefc7-d154-4be6-86ae-4bcafe8aed92","session_start_time":null,"spark_jobs":{"jobs":[{"completionTime":"2023-07-19T14:37:36.916GMT","dataRead":1376,"dataWritten":0,"description":"Job group for statement 5:\nimport java.net.URI\nimport java.util.Calendar\n\nimport scala.collection.mutable.{ListBuffer, Map}\nimport org.apache.spark.sql._\nimport org.apache.spark.sql.types.{ObjectType, _}\nimport org.apache.spark.sql.catalyst._\nimport org.apache.spark.sql.catalyst.catalog._\nimport org.json4s._\nimport org.json4s.JsonAST.JString\nimport org.json4s.jackson.Serialization\nimport org.apache.hadoop.conf.Configuration\nimport org.apache.hadoop.fs.{FileSystem, Path}\nimport org.apache.http.client.methods.{CloseableHttpResponse, HttpPost}\nimport org.apache.http.entity.StringEntity\nimport org.apache.http.impl.client.{CloseableHttpClient, HttpClients}\nimport scala.io.Source\n\n\nvar locationPrefixMappingList = WarehouseMappings.toList.sortBy(pair => pair._1).reverse\n\nval DatabaseType = \"database\"\nval TableType = \"table\"\nval PartitionType = \"partition\"\n\nobject ImportMetadata {\n\n  val spark = SparkSession.builder().getOrCreate()\n\n  case object URISerializer extends CustomSerializer[URI](format => ( {\n    case JString(uri) => new URI(uri)\n  ...","displayName":"collect at <console>:359","jobGroup":"5","jobId":8,"killedTasksSummary":{},"name":"collect at <console>:359","numActiveStages":0,"numActiveTasks":0,"numCompletedIndices":2,"numCompletedStages":1,"numCompletedTasks":2,"numFailedStages":0,"numFailedTasks":0,"numKilledTasks":0,"numSkippedStages":0,"numSkippedTasks":0,"numTasks":2,"rowCount":17,"stageIds":[12],"status":"SUCCEEDED","submissionTime":"2023-07-19T14:37:35.697GMT","usageDescription":""}],"limit":20,"numbers":{"FAILED":0,"RUNNING":0,"SUCCEEDED":1,"UNKNOWN":0},"rule":"ALL_DESC"},"spark_pool":null,"state":"finished","statement_id":5},"text/plain":["StatementMeta(, 1a4eefc7-d154-4be6-86ae-4bcafe8aed92, 5, Finished, Available)"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Start to load stats Wed Jul 19 14:37:32 UTC 2023\n","import java.net.URI\n","import java.util.Calendar\n","import scala.collection.mutable.{ListBuffer, Map}\n","import org.apache.spark.sql._\n","import org.apache.spark.sql.types.{ObjectType, _}\n","import org.apache.spark.sql.catalyst._\n","import org.apache.spark.sql.catalyst.catalog._\n","import org.json4s._\n","import org.json4s.JsonAST.JString\n","import org.json4s.jackson.Serialization\n","import org.apache.hadoop.conf.Configuration\n","import org.apache.hadoop.fs.{FileSystem, Path}\n","import org.apache.http.client.methods.{CloseableHttpResponse, HttpPost}\n","import org.apache.http.entity.StringEntity\n","import org.apache.http.impl.client.{CloseableHttpClient, HttpClients}\n","import scala.io.Source\n","locationPrefixMappingList: List[(String, String)] = List((dbfs:/mnt/stmurgguhms/databricks/warehouse,abfss://c3c00e15-8713-4764-a9dc-43a64cf49eaa@msit-onelake.dfs.fabric.microsoft.com/2e2668a7-9b73-478c-89cc-9ebfbad83a0b/Files/warehouse_dir_dbx), (abfss://hdi-murggu-hms-2023-07-19t13-27-53-906z@stmurgguhms.dfs.core.windows.net/apps/spark/warehouse,abfss://c3c00e15-8713-4764-a9dc-43a64cf49eaa@msit-onelake.dfs.fabric.microsoft.com/2e2668a7-9b73-478c-89cc-9ebfbad83a0b/Files/warehouse_dir_hdi), (abfss://default@stmurgguhms.dfs.core.windows.net/synapse/workspaces/syn-murggu-hms/warehouse,abfss://c3c00e15-8713-4764-a9dc-43a64cf49eaa@msit-onelake.dfs.fabric.microsoft.com/2e2668a7-9b73-478c-89cc-9ebfbad83a0b/Files/warehouse_dir_syn))\n","DatabaseType: String = database\n","TableType: String = table\n","PartitionType: String = partition\n","warning: one deprecation (since 2.11.0); for details, enable `:setting -deprecation' or `:replay -deprecation'\n","defined object ImportMetadata\n","stats: List[ImportMetadata.CatalogStat] = List(CatalogStat(partition,2,Some(hdidb1),Some(dimcustomer_unmanag_part_json)), CatalogStat(partition,2,Some(hdidb2),Some(dimcustomer_unmanag_part_json)), CatalogStat(partition,2,Some(hdidb2),Some(dimcustomer_unmanag_part_csv)), CatalogStat(partition,2,Some(hdidb1),Some(dimcustomer_manag_part_parquet)), CatalogStat(partition,2,Some(hdidb1),Some(dimcustomer_unmanag_part_csv)), CatalogStat(partition,2,Some(hdidb1),Some(dimcustomer_unmanag_part_parquet)), CatalogStat(partition,2,Some(hdidb2),Some(dimcustomer_manag_part_csv)), CatalogStat(partition,2,Some(hdidb2),Some(dimcustomer_manag_part_parquet)), CatalogStat(partition,24,None,None), CatalogStat(database,2,None,None), CatalogStat(table,16,Some(hdidb2),None), CatalogStat(table,16,Some(hdidb1),Non...\n"]}],"source":["%%spark\n","import java.net.URI\n","import java.util.Calendar\n","\n","import scala.collection.mutable.{ListBuffer, Map}\n","import org.apache.spark.sql._\n","import org.apache.spark.sql.types.{ObjectType, _}\n","import org.apache.spark.sql.catalyst._\n","import org.apache.spark.sql.catalyst.catalog._\n","import org.json4s._\n","import org.json4s.JsonAST.JString\n","import org.json4s.jackson.Serialization\n","import org.apache.hadoop.conf.Configuration\n","import org.apache.hadoop.fs.{FileSystem, Path}\n","import org.apache.http.client.methods.{CloseableHttpResponse, HttpPost}\n","import org.apache.http.entity.StringEntity\n","import org.apache.http.impl.client.{CloseableHttpClient, HttpClients}\n","import scala.io.Source\n","\n","\n","var locationPrefixMappingList = WarehouseMappings.toList.sortBy(pair => pair._1).reverse\n","\n","val DatabaseType = \"database\"\n","val TableType = \"table\"\n","val PartitionType = \"partition\"\n","\n","object ImportMetadata {\n","\n","  val spark = SparkSession.builder().getOrCreate()\n","\n","  case object URISerializer extends CustomSerializer[URI](format => ( {\n","    case JString(uri) => new URI(uri)\n","  }, {\n","    case uri: URI => JString(uri.toString())\n","  }))\n","\n","  case object SturctTypeSerializer extends CustomSerializer[StructType](format => ( {\n","    case JString(structType)  => DataType.fromJson(structType).asInstanceOf[StructType]\n","  }, {\n","    case structType: StructType => JString(structType.json)\n","  }))\n","\n","\n","  implicit val formats = DefaultFormats + URISerializer + SturctTypeSerializer\n","\n","  case class CatalogPartitions(database: String, table: String, tablePartitons: Seq[CatalogTablePartition])\n","\n","  case class CatalogTables(database: String, tables: Seq[CatalogTable])\n","\n","  case class CatalogStat(entityType: String, count: Int, database: Option[String], table: Option[String])\n","\n","  def ConvertLocation(location: String) : String = {\n","    var locationMapping = locationPrefixMappingList.find(mapping => {location.startsWith(mapping._1)})\n","\n","    if (locationMapping != None) {\n","      return location.replaceFirst(locationMapping.get._1, locationMapping.get._2)\n","    }\n","\n","    return location;\n","  }\n","\n","  def ConvertCatalogDatabase(database: CatalogDatabase) : CatalogDatabase = {\n","    var convertedDatabase  = new CatalogDatabase(\n","      DatabasePrefix + database.name,\n","      database.description,\n","      new URI(ConvertLocation(database.locationUri.toString())),\n","      database.properties)\n","\n","    return convertedDatabase;\n","  }\n","\n","  def ConvertCatalogStorageFormat(format : CatalogStorageFormat) : CatalogStorageFormat = {\n","\n","    var formatlocation: Option[URI] = None\n","    if (format.locationUri != None) {\n","      formatlocation = Some(new URI(ConvertLocation(format.locationUri.get.toString())))\n","    }\n","\n","    var convertedStorageFormat = new CatalogStorageFormat(\n","      formatlocation,\n","      format.inputFormat,\n","      format.outputFormat,\n","      format.serde,\n","      format.compressed,\n","      format.properties\n","    )\n","\n","    return  convertedStorageFormat;\n","  }\n","\n","  def ConvertCatalogTable(table: CatalogTable) : CatalogTable = {\n","\n","    var dbName = Some(DatabasePrefix + table.identifier.database.get);\n","    var tblName = TablePrefix + table.identifier.table;\n","\n","    var convertedTable = new CatalogTable(\n","      new TableIdentifier(tblName, dbName),\n","      org.apache.spark.sql.catalyst.catalog.CatalogTableType(\"EXTERNAL\"),\n","      ConvertCatalogStorageFormat(table.storage),\n","      table.schema,\n","      table.provider,\n","      table.partitionColumnNames,\n","      table.bucketSpec,\n","      table.owner,\n","      table.createTime,\n","      table.lastAccessTime,\n","      table.createVersion,\n","      table.properties,\n","      table.stats,\n","      table.viewText,\n","      table.comment,\n","      table.unsupportedFeatures,\n","      table.tracksPartitionsInCatalog,\n","      table.schemaPreservesCase,\n","      table.ignoredProperties)\n","\n","    return convertedTable;\n","  }\n","\n","  def ConvertCatalogTablePartition(partition : CatalogTablePartition) : CatalogTablePartition = {\n","    var convertedPartition = new CatalogTablePartition(\n","      partition.spec,\n","      ConvertCatalogStorageFormat(partition.storage),\n","      partition.parameters,\n","      partition.createTime,\n","      partition.lastAccessTime,\n","      partition.stats\n","    );\n","\n","    return convertedPartition;\n","  }\n","\n","  val MaxRetryCount = 3;\n","\n","  def RetriableFunc(func: () => Unit, retryCount: Int = 0): Unit = {\n","    try {\n","      func()\n","    } catch {\n","      case e:Exception => {\n","        if (retryCount < MaxRetryCount){\n","          RetriableFunc(func, retryCount + 1)\n","        } else {\n","          throw e\n","        }\n","      }\n","    }\n","  }\n","\n","  def RetriableQueryFunc(func: () => Object, retryCount: Int = 0): Object = {\n","    try {\n","      func()\n","    } catch {\n","      case e:Exception => {\n","        if (retryCount < MaxRetryCount){\n","          RetriableQueryFunc(func, retryCount + 1)\n","        } else {\n","          throw e\n","        }\n","      }\n","    }\n","  }\n","\n","  // Create DBs\n","\n","  def CreateDatabases(dataPath: String): Int = {\n","\n","    println(\"Start to create databases \" + Calendar.getInstance().getTime())\n","\n","    val ds = spark.read.format(\"text\").load(dataPath)\n","\n","    var createdCount = 0;\n","    var existsDbs = spark.sharedState.externalCatalog.listDatabases()\n","    var data = ds.collect()\n","    var total = data.size\n","\n","    data.foreach(row => {\n","      var jsonString = row.getString(0)\n","      var newDb = ConvertCatalogDatabase(Serialization.read[CatalogDatabase](jsonString))\n","\n","      var exists = existsDbs.contains(newDb.name)\n","      if (exists && !IgnoreIfExists) {\n","\n","        println(createdCount + \"/\" + total + \" databases created. \" + Calendar.getInstance().getTime())\n","        println(\"Database \" + newDb.name + \" already exists\")\n","\n","        throw new Exception(\"Database \" + newDb.name + \" already exists\")\n","      } else if (!exists) {\n","        CreateDatabase(newDb.name)\n","      }\n","\n","      createdCount+=1;\n","\n","      if (createdCount%100 == 0) {\n","        println(createdCount + \"/\" + total + \" databases created\" + Calendar.getInstance().getTime())\n","      }\n","    });\n","\n","    println(\"Databases Created completed. Total \" + createdCount + \" database created. \" + Calendar.getInstance().getTime())\n","    return createdCount\n","  }\n","\n","  def CreateDatabase(dbName: String) = {\n","    RetriableFunc(() => {\n","      val token: String = mssparkutils.credentials.getToken(\"https://analysis.windows.net/powerbi/api\") \n","\n","      val apiUrl = \"https://df-msit-scus-redirect.analysis.windows.net/metadata/workspaces/\" + WorkspaceId +\"/artifacts\"\n","      val payload = s\"\"\"{\"artifactType\": \"Lakehouse\", \"displayName\": \"$dbName\"}\"\"\"\n","\n","      val httpClient: CloseableHttpClient = HttpClients.createDefault()\n","      val httpPost: HttpPost = new HttpPost(apiUrl)\n","      httpPost.addHeader(\"Authorization\", s\"Bearer $token\")\n","      httpPost.addHeader(\"Content-Type\", \"application/json\")\n","      httpPost.setEntity(new StringEntity(payload))\n","\n","      val httpResponse: CloseableHttpResponse = httpClient.execute(httpPost)\n","\n","      httpResponse.close()\n","      httpClient.close()\n","    })\n","  }\n","\n","  // Create Tables\n","\n","  def CreateTables(dataPath: String): Int = {\n","    println(\"Start to create tables \" + Calendar.getInstance().getTime())\n","\n","    val ds = spark.read.format(\"text\").load(dataPath);\n","\n","    var createdCount = 0;\n","    ds.collect().foreach(row => {\n","      var jsonString = row.getString(0)\n","      var tables = Serialization.read[CatalogTables](jsonString);\n","\n","      var existsTables = spark.sharedState.externalCatalog.listTables(DatabasePrefix + tables.database)\n","      var perTables = tables.tables.toParArray\n","\n","      perTables.foreach(table => {\n","        var newTable = ConvertCatalogTable(table)\n","        var exists = existsTables.contains(newTable.identifier.table)\n","        if (exists && !IgnoreIfExists) {\n","\n","          println(createdCount + \" tables created. \" + Calendar.getInstance().getTime())\n","          println(\"Table \" + newTable.identifier.database + \".\" + newTable.identifier.table + \" already exists\")\n","\n","          throw new Exception(\"Table \" + newTable.identifier.database + \".\" + newTable.identifier.table + \" already exists\")\n","        } else if (!exists) {\n","          CreateTable(newTable)\n","        }\n","\n","        createdCount+=1;\n","      })\n","\n","      println(createdCount + \" tables created\" + Calendar.getInstance().getTime())\n","    })\n","\n","    println(\"Tables Created completed. Total \" + createdCount + \" table created. \" + Calendar.getInstance().getTime())\n","    return createdCount\n","  }\n","\n","  def CreateTable(table:CatalogTable) = {\n","    RetriableFunc(() => {\n","      spark.sharedState.externalCatalog.createTable(table, IgnoreIfExists)\n","    })\n","  }\n","\n","  def ValidateTablePath(dataPath: String) = {\n","    println(\"Start to validate table path \" + Calendar.getInstance().getTime())\n","\n","    val ds = spark.read.format(\"text\").load(dataPath)\n","    var hadoopConf = spark.sparkContext.hadoopConfiguration\n","\n","    ds.collect().foreach(row => {\n","      var jsonString = row.getString(0)\n","      var tables = Serialization.read[CatalogTables](jsonString);\n","\n","      tables.tables.toParArray.foreach(table => {\n","        var newTable = ConvertCatalogTable(table)\n","        try{\n","          var p = new Path(newTable.location);\n","          var fs = p.getFileSystem(hadoopConf);\n","        } catch {\n","          case e:Exception => {\n","            throw new Exception(\"Validate table path failed. Table: \" + newTable.identifier.database.getOrElse() + \".\" + newTable.identifier.table + \", Location: \" +  newTable.location + \" , exception: \" + e)\n","          }\n","        }\n","      })\n","    })\n","\n","    println(\"Validate table path completed\")\n","  }\n","\n","  // Create Partitions\n","\n","  def CreatePartitions(dataPath: String): Int = {\n","    println(\"Start to create partitions \" + Calendar.getInstance().getTime())\n","\n","    val ds = spark.read.format(\"text\").load(dataPath);\n","\n","    var createdCount = 0;\n","    ds.collect().foreach(row => {\n","      var jsonString = row.getString(0)\n","      var parts = Serialization.read[CatalogPartitions](jsonString);\n","\n","      var catalogTablePartitions = new ListBuffer[CatalogTablePartition]()\n","      parts.tablePartitons.foreach( part => {\n","        catalogTablePartitions += ConvertCatalogTablePartition(part)\n","      })\n","\n","      RetriableFunc(() => {\n","        spark.sharedState.externalCatalog.createPartitions(DatabasePrefix + parts.database, TablePrefix + parts.table, catalogTablePartitions, IgnoreIfExists)\n","      })\n","\n","      createdCount+=catalogTablePartitions.size;\n","      println(createdCount +  \" partitions created\" + Calendar.getInstance().getTime())\n","    });\n","\n","    println(\"Partition Created completed. Total \" + createdCount + \" partition created. \" + Calendar.getInstance().getTime())\n","    return createdCount\n","  }\n","\n","  def LoadStats(dataPath: String): List[CatalogStat] = {\n","    println(\"Start to load stats \" + Calendar.getInstance().getTime())\n","\n","    val ds = spark.read.format(\"text\").load(dataPath);\n","\n","    var statBuffer = new ListBuffer[CatalogStat];\n","    ds.collect().foreach(row => {\n","      var jsonString = row.getString(0)\n","      statBuffer.append(Serialization.read[CatalogStat](jsonString))\n","    })\n","\n","    return statBuffer.toList\n","  }\n","\n","  def ValidateImportResult(entityType: String, createdCount: Int, stats: List[CatalogStat]):Boolean = {\n","    var mappingStat = stats.find(stat => stat.entityType == entityType && stat.database == None && stat.table == None);\n","    if (mappingStat == None) {\n","      println(\"Validated failed. Failed to get orignal \" + entityType + \" count\")\n","      return false\n","    }\n","\n","    if (mappingStat.get.count != createdCount) {\n","      println(\"Validated failed. Catalog object count missmatch. Expected \" + entityType + \" count is \" + mappingStat.get.count + \", but created \" + entityType + \" count is \" + createdCount);\n","      return false;\n","    }\n","\n","    println(\"Validated passed. Catalog objects are created as expected. \" + createdCount + \" \" + entityType + \" are created.\" )\n","    return true\n","  }\n","\n","  def ImportCatalogObjectsFromFile(inputPath: String) = {\n","\n","    val dbsPath = inputPath + \"databases\";\n","    val tablesPath = inputPath + \"tables\";\n","    val partPath = inputPath + \"partitions\";\n","\n","    CreateDatabases(dbsPath)\n","    CreateTables(tablesPath)\n","    CreatePartitions(partPath)\n","  }\n","}\n","\n","var stats = ImportMetadata.LoadStats(IntermediateFolderPath + \"/catalogObjectStats\")"]},{"cell_type":"code","execution_count":4,"id":"482efd6b-1866-42e0-b37b-7101b9d1d64e","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"scala"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2023-07-19T14:37:47.9005394Z","execution_start_time":"2023-07-19T14:37:44.4144806Z","livy_statement_state":"available","parent_msg_id":"2cdb0459-184a-4178-88b4-4906dd7545e4","queued_time":"2023-07-19T14:37:44.1482679Z","session_id":"1a4eefc7-d154-4be6-86ae-4bcafe8aed92","session_start_time":null,"spark_jobs":{"jobs":[{"completionTime":"2023-07-19T14:37:46.921GMT","dataRead":48706,"dataWritten":0,"description":"Job group for statement 6:\n// Validate table path\nImportMetadata.ValidateTablePath(IntermediateFolderPath + \"/tables\")","displayName":"collect at <console>:304","jobGroup":"6","jobId":9,"killedTasksSummary":{},"name":"collect at <console>:304","numActiveStages":0,"numActiveTasks":0,"numCompletedIndices":2,"numCompletedStages":1,"numCompletedTasks":2,"numFailedStages":0,"numFailedTasks":0,"numKilledTasks":0,"numSkippedStages":0,"numSkippedTasks":0,"numTasks":2,"rowCount":2,"stageIds":[13],"status":"SUCCEEDED","submissionTime":"2023-07-19T14:37:46.137GMT","usageDescription":""}],"limit":20,"numbers":{"FAILED":0,"RUNNING":0,"SUCCEEDED":1,"UNKNOWN":0},"rule":"ALL_DESC"},"spark_pool":null,"state":"finished","statement_id":6},"text/plain":["StatementMeta(, 1a4eefc7-d154-4be6-86ae-4bcafe8aed92, 6, Finished, Available)"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Start to validate table path Wed Jul 19 14:37:44 UTC 2023\n","Validate table path completed\n"]}],"source":["%%spark\n","// Validate table path\n","ImportMetadata.ValidateTablePath(IntermediateFolderPath + \"/tables\")"]},{"cell_type":"code","execution_count":5,"id":"29ca55a3-88fd-4b98-80b2-2654b3df13f3","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2023-07-19T14:38:15.72753Z","execution_start_time":"2023-07-19T14:37:52.8019843Z","livy_statement_state":"available","parent_msg_id":"3347183b-1f06-4b77-a764-86d514b5a2b5","queued_time":"2023-07-19T14:37:52.5201215Z","session_id":"1a4eefc7-d154-4be6-86ae-4bcafe8aed92","session_start_time":null,"spark_jobs":{"jobs":[{"completionTime":"2023-07-19T14:38:08.118GMT","dataRead":386,"dataWritten":0,"description":"Job group for statement 7:\n// Import Databases\nvar createdDb = ImportMetadata.CreateDatabases(IntermediateFolderPath + \"/databases\")\nImportMetadata.ValidateImportResult(DatabaseType, createdDb, stats)","displayName":"collect at <console>:205","jobGroup":"7","jobId":10,"killedTasksSummary":{},"name":"collect at <console>:205","numActiveStages":0,"numActiveTasks":0,"numCompletedIndices":2,"numCompletedStages":1,"numCompletedTasks":2,"numFailedStages":0,"numFailedTasks":0,"numKilledTasks":0,"numSkippedStages":0,"numSkippedTasks":0,"numTasks":2,"rowCount":2,"stageIds":[14],"status":"SUCCEEDED","submissionTime":"2023-07-19T14:38:07.460GMT","usageDescription":""}],"limit":20,"numbers":{"FAILED":0,"RUNNING":0,"SUCCEEDED":1,"UNKNOWN":0},"rule":"ALL_DESC"},"spark_pool":null,"state":"finished","statement_id":7},"text/plain":["StatementMeta(, 1a4eefc7-d154-4be6-86ae-4bcafe8aed92, 7, Finished, Available)"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Start to create databases Wed Jul 19 14:37:53 UTC 2023\n","Databases Created completed. Total 2 database created. Wed Jul 19 14:38:14 UTC 2023\n","Validated passed. Catalog objects are created as expected. 2 database are created.\n","createdDb: Int = 2\n","res17: Boolean = true\n"]}],"source":["// Import Databases\n","var createdDb = ImportMetadata.CreateDatabases(IntermediateFolderPath + \"/databases\")\n","ImportMetadata.ValidateImportResult(DatabaseType, createdDb, stats)"]},{"cell_type":"code","execution_count":6,"id":"d309fe7d-66ea-45dd-affe-2444c044f555","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"scala"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2023-07-19T14:38:21.3369523Z","execution_start_time":"2023-07-19T14:38:20.5523452Z","livy_statement_state":"available","parent_msg_id":"85a753bf-aaf2-4bdc-b34b-8b73163bdcc0","queued_time":"2023-07-19T14:38:20.2635376Z","session_id":"1a4eefc7-d154-4be6-86ae-4bcafe8aed92","session_start_time":null,"spark_jobs":{"jobs":[],"limit":20,"numbers":{"FAILED":0,"RUNNING":0,"SUCCEEDED":0,"UNKNOWN":0},"rule":"ALL_DESC"},"spark_pool":null,"state":"finished","statement_id":8},"text/plain":["StatementMeta(, 1a4eefc7-d154-4be6-86ae-4bcafe8aed92, 8, Finished, Available)"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["res19: Seq[String] = Buffer(samplelk, lk_syn_blog1, mur_hms_01, synpydb, syndb1, syndb2, dbxdb3, dbxdb4, hdidb1, hdidb2)\n"]}],"source":["%%spark\n","// Validate Lakehouse (database) creation\n","spark.sharedState.externalCatalog.listDatabases()"]},{"cell_type":"code","execution_count":7,"id":"b43b002a-3926-41c6-9686-8d66b6e776cc","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"scala"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2023-07-19T14:38:49.9258772Z","execution_start_time":"2023-07-19T14:38:24.6879372Z","livy_statement_state":"available","parent_msg_id":"0fa215e4-13a2-45ce-a6e6-1890867d3f35","queued_time":"2023-07-19T14:38:24.3902227Z","session_id":"1a4eefc7-d154-4be6-86ae-4bcafe8aed92","session_start_time":null,"spark_jobs":{"jobs":[{"completionTime":"2023-07-19T14:38:27.184GMT","dataRead":48706,"dataWritten":0,"description":"Job group for statement 9:\n// Import Tables\nvar createdTbl = ImportMetadata.CreateTables(IntermediateFolderPath + \"/tables\")\nImportMetadata.ValidateImportResult(TableType, createdTbl, stats)","displayName":"collect at <console>:262","jobGroup":"9","jobId":11,"killedTasksSummary":{},"name":"collect at <console>:262","numActiveStages":0,"numActiveTasks":0,"numCompletedIndices":2,"numCompletedStages":1,"numCompletedTasks":2,"numFailedStages":0,"numFailedTasks":0,"numKilledTasks":0,"numSkippedStages":0,"numSkippedTasks":0,"numTasks":2,"rowCount":2,"stageIds":[15],"status":"SUCCEEDED","submissionTime":"2023-07-19T14:38:26.398GMT","usageDescription":""}],"limit":20,"numbers":{"FAILED":0,"RUNNING":0,"SUCCEEDED":1,"UNKNOWN":0},"rule":"ALL_DESC"},"spark_pool":null,"state":"finished","statement_id":9},"text/plain":["StatementMeta(, 1a4eefc7-d154-4be6-86ae-4bcafe8aed92, 9, Finished, Available)"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Start to create tables Wed Jul 19 14:38:25 UTC 2023\n","16 tables createdWed Jul 19 14:38:39 UTC 2023\n","32 tables createdWed Jul 19 14:38:49 UTC 2023\n","Tables Created completed. Total 32 table created. Wed Jul 19 14:38:49 UTC 2023\n","Validated passed. Catalog objects are created as expected. 32 table are created.\n","createdTbl: Int = 32\n","res21: Boolean = true\n"]}],"source":["%%spark\n","// Import Tables\n","var createdTbl = ImportMetadata.CreateTables(IntermediateFolderPath + \"/tables\")\n","ImportMetadata.ValidateImportResult(TableType, createdTbl, stats)"]},{"cell_type":"code","execution_count":8,"id":"f79e4008-8085-4065-8d27-898ddc2fa106","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"scala"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2023-07-19T14:39:00.5198095Z","execution_start_time":"2023-07-19T14:38:50.2102117Z","livy_statement_state":"available","parent_msg_id":"71c4f009-ba5a-4f15-ac27-aacc24f69871","queued_time":"2023-07-19T14:38:29.1928595Z","session_id":"1a4eefc7-d154-4be6-86ae-4bcafe8aed92","session_start_time":null,"spark_jobs":{"jobs":[{"completionTime":"2023-07-19T14:38:52.230GMT","dataRead":19488,"dataWritten":0,"description":"Job group for statement 10:\n// Import Partitions\nvar createdPart = ImportMetadata.CreatePartitions(IntermediateFolderPath + \"/partitions\")\nImportMetadata.ValidateImportResult(PartitionType, createdPart, stats)","displayName":"collect at <console>:332","jobGroup":"10","jobId":12,"killedTasksSummary":{},"name":"collect at <console>:332","numActiveStages":0,"numActiveTasks":0,"numCompletedIndices":2,"numCompletedStages":1,"numCompletedTasks":2,"numFailedStages":0,"numFailedTasks":0,"numKilledTasks":0,"numSkippedStages":0,"numSkippedTasks":0,"numTasks":2,"rowCount":12,"stageIds":[16],"status":"SUCCEEDED","submissionTime":"2023-07-19T14:38:51.562GMT","usageDescription":""}],"limit":20,"numbers":{"FAILED":0,"RUNNING":0,"SUCCEEDED":1,"UNKNOWN":0},"rule":"ALL_DESC"},"spark_pool":null,"state":"finished","statement_id":10},"text/plain":["StatementMeta(, 1a4eefc7-d154-4be6-86ae-4bcafe8aed92, 10, Finished, Available)"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Start to create partitions Wed Jul 19 14:38:50 UTC 2023\n","2 partitions createdWed Jul 19 14:38:52 UTC 2023\n","4 partitions createdWed Jul 19 14:38:53 UTC 2023\n","6 partitions createdWed Jul 19 14:38:54 UTC 2023\n","8 partitions createdWed Jul 19 14:38:54 UTC 2023\n","10 partitions createdWed Jul 19 14:38:55 UTC 2023\n","12 partitions createdWed Jul 19 14:38:55 UTC 2023\n","14 partitions createdWed Jul 19 14:38:56 UTC 2023\n","16 partitions createdWed Jul 19 14:38:57 UTC 2023\n","18 partitions createdWed Jul 19 14:38:57 UTC 2023\n","20 partitions createdWed Jul 19 14:38:58 UTC 2023\n","22 partitions createdWed Jul 19 14:38:58 UTC 2023\n","24 partitions createdWed Jul 19 14:38:59 UTC 2023\n","Partition Created completed. Total 24 partition created. Wed Jul 19 14:38:59 UTC 2023\n","Validated passed. Catalog objects are created as expected. 24 partition are created.\n","createdPart: Int = 24\n","res23: Boolean = true\n"]}],"source":["%%spark\n","// Import Partitions\n","var createdPart = ImportMetadata.CreatePartitions(IntermediateFolderPath + \"/partitions\")\n","ImportMetadata.ValidateImportResult(PartitionType, createdPart, stats)"]}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"display_name":"Synapse PySpark","name":"synapse_pyspark"},"language_info":{"name":"scala"},"microsoft":{"host":{"synapse_widget":{"state":{},"token":"278e800a-6fb3-4c50-9b22-6250c936140e"}},"language":"scala","ms_spell_check":{"ms_spell_check_language":"en"}},"notebook_environment":{},"nteract":{"version":"nteract-front-end@1.0.0"},"save_output":true,"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{},"enableDebugMode":false}},"synapse_widget":{"state":{},"version":"0.1"},"trident":{"lakehouse":{"default_lakehouse":"2e2668a7-9b73-478c-89cc-9ebfbad83a0b","default_lakehouse_name":"lk_syn_blog1","default_lakehouse_workspace_id":"c3c00e15-8713-4764-a9dc-43a64cf49eaa","known_lakehouses":[{"id":"5446d04e-7c62-4527-9658-95a9cd3622df"},{"id":"2e2668a7-9b73-478c-89cc-9ebfbad83a0b"}]}},"widgets":{}},"nbformat":4,"nbformat_minor":5}
